{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1pI8RtPdujoGKyvY_o38OwHlYmMv49sQm",
      "authorship_tag": "ABX9TyN1x/zACq0cIka+D87YiSx3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BKousha/FloorPlanSegmentation/blob/main/training_TF_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK1gF664x5HK",
        "outputId": "dcec9d7b-a9ab-4498-b38d-f681e72da193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'Colab Notebooks'\n",
            "'Copy of Predictive Maintenance Checklist.gdoc'\n",
            " FloorPlan_samples\n",
            " model_best_val_loss_var.pkl\n",
            " Processed_Floor_Plans\n",
            " ShotBot\n",
            "'SNN_soft shadow network for image compositing.pdf'\n",
            " test.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install segmentation_models -q\n",
        "# ! pip install -U segmentation-models==0.2.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5RCm9SATFQF",
        "outputId": "64d667e3-c5cb-411f-a370-666a021bfe7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D,Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib as mlp\n",
        "\n",
        "\n",
        "# ! pip install --upgrade keras\n",
        "import segmentation_models as sm\n",
        "\n",
        "from tensorflow.keras.saving import get_custom_objects\n"
      ],
      "metadata": {
        "id": "9JG4Z1ym0WRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd159387-898b-437a-e8d8-d63448a0c431"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGKI4zG6R_T3",
        "outputId": "06512496-e2e7-4fec-876e-3a6d9da0504f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class mapping for merging\n",
        "class_names = {\n",
        "    0: \"background\",\n",
        "    1: \"room\",\n",
        "    2: \"hallway\",\n",
        "    3: \"kitchen\",\n",
        "    4: \"columns\",\n",
        "    5: \"mep\",\n",
        "    6: \"windows\",\n",
        "    7: \"doors\",\n",
        "    8: \"glass_doors\",\n",
        "    9: \"bathrooms\",\n",
        "    10: \"elevators\",\n",
        "    11: \"elevator_doors\",\n",
        "    12: \"stairs\",\n",
        "    13: \"storage\",\n",
        "    14: \"electrical\"\n",
        "}\n",
        "# # class_mapping  = {\n",
        "# #     0:  [0],   # Background\n",
        "# #     1:  [1],   # Room\n",
        "# #     2:  [2],   # Hallway\n",
        "# #     3:  [3],   # Kitchen\n",
        "# #     4:  [4],   # Columns\n",
        "# #     5:  [6],   # windows\n",
        "# #     6:  [7,8], # Doors,Glass Doors\n",
        "# #     7:  [9],   # Bathrooms\n",
        "# #     8:  [11],  # elevator_doors\n",
        "# #     9:  [5, 10, 12, 13],  # MEP, Elevators, Stairs, Storage\n",
        "# #     10: [14]   # Electrical\n",
        "# # }\n",
        "# def translate_array(arr):\n",
        "#     # Mapping dictionary for category translation\n",
        "#     translation_dict = {\n",
        "#         5: 9,   # Merge MEP into Bathrooms\n",
        "#         10: 9,  # Merge Elevators into Bathrooms\n",
        "#         12: 9,  # Merge Stairs into Bathrooms\n",
        "#         13: 9,  # Merge Storage into Bathrooms\n",
        "#         7: 8,   # Merge Doors into Glass Doors\n",
        "#     }\n",
        "\n",
        "#     # Create a new array by mapping the original array using the translation dictionary\n",
        "#     translated_arr = np.vectorize(translation_dict.get)(arr)\n",
        "\n",
        "#     return translated_arr"
      ],
      "metadata": {
        "id": "RS7n_kWJLs61"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the necessary parameters\n",
        "image_dir = \"/content/drive/MyDrive/Processed_Floor_Plans/smaller_images/temp_images\"\n",
        "mask_dir = \"/content/drive/MyDrive/Processed_Floor_Plans/smaller_images/temp_masks\"\n",
        "\n",
        "\n",
        "def listdir_fullpath(d):\n",
        "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
        "\n",
        "# Load the image and mask files\n",
        "image_files = []\n",
        "mask_files = []\n",
        "for folder_name in ['1', '2', '4', '8']:\n",
        "    folder_image_dir = os.path.join(image_dir, folder_name)\n",
        "    folder_mask_dir = os.path.join(mask_dir, folder_name)\n",
        "\n",
        "    image_files.extend(sorted(listdir_fullpath(folder_image_dir)))\n",
        "    mask_files.extend(sorted(listdir_fullpath(folder_mask_dir)))\n",
        "\n",
        "print(len(image_files))\n",
        "print(len(mask_files))\n",
        "\n"
      ],
      "metadata": {
        "id": "3KbWbh_YGxSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# from tqdm import tqdm\n",
        "# threshold=2000\n",
        "# class_counts = {class_name: 0 for class_name in class_names.values()}\n",
        "\n",
        "# for mask_file in tqdm(mask_files):\n",
        "#     # Load the mask image\n",
        "\n",
        "#     mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "#     # Calculate the count of each class in the mask image\n",
        "#     for class_value, class_name in class_names.items():\n",
        "#         class_pixels = np.sum(mask == class_value)\n",
        "#         if class_pixels >= threshold:\n",
        "#             class_counts[class_name] += 1\n",
        "\n",
        "\n",
        "# total_files = len(mask_files)\n",
        "# class_percentages = {class_name: (count / total_files) * 100 for class_name, count in class_counts.items()}\n",
        "\n",
        "# # Print the results\n",
        "# for class_name, percentage in class_percentages.items():\n",
        "#     print(f\"Class: {class_name} - Percentage: {percentage}%\")"
      ],
      "metadata": {
        "id": "66owvBJX0kzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "target_size = (512, 512)\n",
        "num_classes = 14\n",
        "Number_Category = 14"
      ],
      "metadata": {
        "id": "XRuBEUhWG1l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, image_files, mask_files, batch_size, target_size, class_code,shuffle=True,background_threshold=0.9,random_state=2023):\n",
        "        self.image_files = image_files\n",
        "        self.mask_files = mask_files\n",
        "        self.class_code = class_code\n",
        "        #self.image_dir = image_dir\n",
        "        #$self.mask_dir = mask_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.shuffle = shuffle\n",
        "        #self.num_classes = num_classes\n",
        "        self.background_threshold=background_threshold\n",
        "        np.random.seed(random_state)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_masks = []\n",
        "        batch_files = []\n",
        "\n",
        "        for i in batch_indexes:\n",
        "            image_file = self.image_files[i]\n",
        "            mask_file = self.mask_files[i]\n",
        "\n",
        "\n",
        "            #image_path = os.path.join(self.image_dir, image_file)\n",
        "            #mask_path = os.path.join(self.mask_dir, mask_file)\n",
        "\n",
        "            mask = tf.keras.preprocessing.image.load_img(mask_file, color_mode=\"grayscale\", target_size=self.target_size)\n",
        "            mask = tf.keras.preprocessing.image.img_to_array(mask)\n",
        "            mask = self.preprocess_mask(mask)\n",
        "\n",
        "            background_pixels = np.count_nonzero(mask == 0)\n",
        "            total_pixels = mask.size\n",
        "            background_percentage = background_pixels / total_pixels\n",
        "\n",
        "            # Ignore samples where the background percentage exceeds the threshold\n",
        "            if background_percentage > self.background_threshold:\n",
        "                #print(background_percentage)\n",
        "                continue\n",
        "\n",
        "            image = tf.keras.preprocessing.image.load_img(image_file, color_mode=\"rgb\", target_size=self.target_size)\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            image = image / 255.0\n",
        "\n",
        "            batch_images.append(image)\n",
        "            batch_masks.append(mask)\n",
        "            batch_files.append(image_file)\n",
        "            #print(image_file)\n",
        "\n",
        "        return np.array(batch_images), np.array(batch_masks),batch_files\n",
        "    def on_epoch_end(self):\n",
        "       #return super().on_epoch_end()\n",
        "       self.indexes = np.arange(len(self.image_files))\n",
        "       if self.shuffle:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "    def preprocess_mask(self, mask):\n",
        "        # merged_mask = np.zeros(mask.shape[:2])\n",
        "\n",
        "        # for new_class, old_classes in class_mapping.items():\n",
        "        #     merged_mask[np.isin(mask, old_classes)] = new_class\n",
        "        #print(self.class_code)\n",
        "        modified_mask = np.round((mask.astype(np.float64)*Number_Category/255)).astype(np.uint8)\n",
        "        modified_mask = np.where(modified_mask == self.class_code, 1, 0)\n",
        "        return modified_mask"
      ],
      "metadata": {
        "id": "gXkWGmxmDoKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the files into training and validation sets\n",
        "train_files, val_files,mask_trin_file,mask_val_files = train_test_split(image_files, mask_files, test_size=0.1, random_state=42)\n",
        "len(mask_trin_file)"
      ],
      "metadata": {
        "id": "6tVT3O3OEaeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_them(data_generator,num_batches=4):\n",
        "\n",
        "  for _ in range(num_batches):\n",
        "    sample_image, sample_mask,batch_files = data_generator[_]\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      # Plot the original image and the predicted mask\n",
        "      try:\n",
        "        img=sample_image[i]\n",
        "        #image_array_scaled = np.round((sample_mask[i].astype(np.float64)*Number_Category/255)).astype(np.uint8)\n",
        "        msk=sample_mask[i]\n",
        "        txt=batch_files[i]\n",
        "        print(txt)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "        axes[0].imshow(img)\n",
        "        axes[0].set_title('Original Image')\n",
        "        axes[0].axis('off')\n",
        "        axes[1].imshow(msk)\n",
        "        axes[1].set_title('Mask')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        axes[2].imshow(img)\n",
        "        axes[2].axis('off')\n",
        "        axes[2].imshow(msk,alpha=0.6)#, cmap=cmap,norm=norm\n",
        "        axes[2].set_title('Original Image and mask overlaped')\n",
        "\n",
        "        #axes[2].legend(handles=legend_patches, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        j=j+1\n",
        "        print(j)\n",
        "      except:\n",
        "        pass\n",
        "\n"
      ],
      "metadata": {
        "id": "IPufDxwLFZsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generators=[]\n",
        "val_data_generators=[]\n",
        "for i in range(1,14):\n",
        "    #tmp_train_data_generator = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=i,background_threshold=0.99)\n",
        "    tmp_train_data_generator = SegmentationDataGenerator(train_files, mask_trin_file, batch_size, target_size, class_code=i,shuffle=True,background_threshold=0.99)\n",
        "    tmp_val_data_generator   = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=i,shuffle=False,background_threshold=0.99)\n",
        "    #plot_them(val_data_generator_1,num_batches=1)\n",
        "    train_data_generators.append(tmp_train_data_generator)\n",
        "    val_data_generators.append(tmp_val_data_generator)\n"
      ],
      "metadata": {
        "id": "RYl3qJWeJl2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch_size)\n",
        "for _ in range(4):\n",
        "    sample_image, sample_mask,batch_files = train_data_generators[0][_]\n",
        "    print(sample_image.shape,sample_mask.shape)"
      ],
      "metadata": {
        "id": "7y7U3AcURPPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rooms"
      ],
      "metadata": {
        "id": "ZngWfgVd27W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#val_data_generator_1 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=1,background_threshold=0.99)\n",
        "#plot_them(val_data_generator_1,num_batches=1)"
      ],
      "metadata": {
        "id": "UAhjKOgc1GYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hallways"
      ],
      "metadata": {
        "id": "hjPu2Hes2-Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_2 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=2,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_2,num_batches=1)"
      ],
      "metadata": {
        "id": "srZ0I7Xr1bef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kitchens"
      ],
      "metadata": {
        "id": "lvbdQtGx3BEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_3 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=3,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_3)"
      ],
      "metadata": {
        "id": "DAqZTVLV3EeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Columns"
      ],
      "metadata": {
        "id": "IbxKzjRr3PmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_4 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=4,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_4)"
      ],
      "metadata": {
        "id": "-cwOp_aF3Sal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MEPs"
      ],
      "metadata": {
        "id": "pQ_LvZxK3eBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_5 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=5,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_5,num_batches=20)"
      ],
      "metadata": {
        "id": "BqyYp7D03fjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Windows"
      ],
      "metadata": {
        "id": "9Zkm-lMP4FoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_6 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=6,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_6)"
      ],
      "metadata": {
        "id": "t5ugxzLi0u5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# doors"
      ],
      "metadata": {
        "id": "w1flK-9Y4PMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_7 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=7,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_7)\n"
      ],
      "metadata": {
        "id": "UYKZGMWgoYma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# glass_doors"
      ],
      "metadata": {
        "id": "Y7CEBSnU4Vdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_8 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=8,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_8,num_batches=20)\n",
        "\n"
      ],
      "metadata": {
        "id": "B7k8KAym4Soz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bathrooms"
      ],
      "metadata": {
        "id": "XSHAqGmp42Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_9 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=9,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_9,num_batches=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "F_3N7hcG41o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elevators"
      ],
      "metadata": {
        "id": "w8YCFLIE5m2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_10 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=10,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_10,num_batches=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "BGdFtmB55mp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elevator doors"
      ],
      "metadata": {
        "id": "VVNRIVpW5y1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_11 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=11,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_11,num_batches=20)"
      ],
      "metadata": {
        "id": "A9MQPkXq5ynn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stairs"
      ],
      "metadata": {
        "id": "YorJT_S96UyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_12 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=12,background_threshold=0.99)\n",
        "# plot_them(val_data_generator_12,num_batches=5)"
      ],
      "metadata": {
        "id": "T9ARbIB_6Upi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storage"
      ],
      "metadata": {
        "id": "xjZFzdvi6o4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_13 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=13,background_threshold=0.90)\n",
        "# plot_them(val_data_generator_13,num_batches=5)"
      ],
      "metadata": {
        "id": "OEE5EG9N6oxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# electrical"
      ],
      "metadata": {
        "id": "FTwNzSLm7Fce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data_generator_14 = SegmentationDataGenerator(val_files, mask_val_files, batch_size, target_size, class_code=14,background_threshold=0.90)\n",
        "# plot_them(val_data_generator_14,num_batches=50)"
      ],
      "metadata": {
        "id": "DkHLSc577FTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u-k3G4CZ6USP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://tensorlayer.readthedocs.io/en/latest/_modules/tensorlayer/cost.html#dice_coe\n",
        "def dice_coe(output, target, axis = None, smooth=1e-10):\n",
        "    output = tf.dtypes.cast( tf.math.greater(output, 0.5), tf. float32 )\n",
        "    target = tf.dtypes.cast( tf.math.greater(target, 0.5), tf. float32 )\n",
        "    inse = tf.reduce_sum(output * target, axis=axis)\n",
        "    l = tf.reduce_sum(output, axis=axis)\n",
        "    r = tf.reduce_sum(target, axis=axis)\n",
        "\n",
        "    dice = (2. * inse + smooth) / (l + r + smooth)\n",
        "    dice = tf.reduce_mean(dice, name='dice_coe')\n",
        "    return dice\n",
        "\n",
        "# https://www.kaggle.com/kool777/training-hubmap-eda-tf-keras-tpu\n",
        "def tversky(y_true, y_pred, alpha=0.7, beta=0.3, smooth=1):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true, y_pred)\n",
        "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
        "    tv = tversky(y_true, y_pred)\n",
        "    return K.pow((1 - tv), gamma)\n",
        "\n",
        "get_custom_objects().update({\"focal_tversky\": focal_tversky_loss})"
      ],
      "metadata": {
        "id": "yzXZV-LFLMQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.set_image_data_format('channels_last')\n",
        "\n",
        "model = sm.Unet('resnet34', classes=1, activation='sigmoid')\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.01),\n",
        "                      loss = tf.keras.losses.BinaryCrossentropy(),#'focal_tversky',\n",
        "                      metrics=[dice_coe,'accuracy'])\n"
      ],
      "metadata": {
        "id": "WbYAsrjOHCkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the data generators\n",
        "history=model.fit(train_data_generators[0], epochs=10, validation_data=val_data_generators[0])\n"
      ],
      "metadata": {
        "id": "lCC7VSX7WAe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved model\n",
        "best_model = tf.keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "val_loss, val_acc = model.evaluate(val_data_generators[0])\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_acc)\n"
      ],
      "metadata": {
        "id": "XWccOhPkHJnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the loss values from the history object\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the loss values\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, 'g', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Loss Function')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D08feMJYKFlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}