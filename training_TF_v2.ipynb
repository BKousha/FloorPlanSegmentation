{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BKousha/FloorPlanSegmentation/blob/main/training_TF_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK1gF664x5HK",
        "outputId": "298a1e3c-7c22-4d47-fceb-135900bc756e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'Colab Notebooks'\n",
            "'Copy of Predictive Maintenance Checklist.gdoc'\n",
            " FloorPlan_samples\n",
            " model_best_val_loss_var.pkl\n",
            " Processed_Floor_Plans\n",
            " ShotBot\n",
            "'SNN_soft shadow network for image compositing.pdf'\n",
            " test.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d5RCm9SATFQF"
      },
      "outputs": [],
      "source": [
        "\n",
        "! pip install segmentation_models -q\n",
        "# ! pip install -U segmentation-models==0.2.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9JG4Z1ym0WRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb235d3-cf72-41c1-bbfb-80ac234e97ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D,Conv2DTranspose\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib as mlp\n",
        "\n",
        "\n",
        "# ! pip install --upgrade keras\n",
        "import segmentation_models as sm\n",
        "\n",
        "from tensorflow.keras.saving import get_custom_objects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGKI4zG6R_T3",
        "outputId": "15823ebd-854d-4986-cec4-40b77cc0aa37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n",
            "Training device: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "\n",
        "try: # detect TPUs\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "except ValueError: # no TPU found, detect GPUs\n",
        "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "\n",
        "try:\n",
        "  # Check the device being used for training\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "\n",
        "  if device_name != '/device:GPU:0':\n",
        "      device_name = tf.test.tpu_device_name()\n",
        "\n",
        "  if device_name == '':\n",
        "      device_name = 'CPU'\n",
        "except:\n",
        "  pass\n",
        "print('Training device:', device_name)\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RS7n_kWJLs61"
      },
      "outputs": [],
      "source": [
        "# Define the class mapping for merging\n",
        "class_names = {\n",
        "    0: \"background\",\n",
        "    1: \"room\",\n",
        "    2: \"hallway\",\n",
        "    3: \"kitchen\",\n",
        "    4: \"columns\",\n",
        "    5: \"mep\",\n",
        "    6: \"windows\",\n",
        "    7: \"doors\",\n",
        "    8: \"glass_doors\",\n",
        "    9: \"bathrooms\",\n",
        "    10: \"elevators\",\n",
        "    11: \"elevator_doors\",\n",
        "    12: \"stairs\",\n",
        "    13: \"storage\",\n",
        "    14: \"electrical\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "3KbWbh_YGxSi",
        "outputId": "4d78d5c2-4b29-4f98-a857-ec909297b63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24903\n",
            "24903\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                filename  background  \\\n",
              "0      /content/drive/MyDrive/Processed_Floor_Plans/s...    0.591652   \n",
              "1      /content/drive/MyDrive/Processed_Floor_Plans/s...    0.752861   \n",
              "2      /content/drive/MyDrive/Processed_Floor_Plans/s...    0.367546   \n",
              "3      /content/drive/MyDrive/Processed_Floor_Plans/s...    0.450470   \n",
              "4      /content/drive/MyDrive/Processed_Floor_Plans/s...    0.543015   \n",
              "...                                                  ...         ...   \n",
              "24898  /content/drive/MyDrive/Processed_Floor_Plans/s...    0.614685   \n",
              "24899  /content/drive/MyDrive/Processed_Floor_Plans/s...    0.644474   \n",
              "24900  /content/drive/MyDrive/Processed_Floor_Plans/s...    0.597298   \n",
              "24901  /content/drive/MyDrive/Processed_Floor_Plans/s...    0.552479   \n",
              "24902  /content/drive/MyDrive/Processed_Floor_Plans/s...    0.727989   \n",
              "\n",
              "           room   hallway   kitchen   columns       mep   windows     doors  \\\n",
              "0      0.118961  0.007053  0.278271  0.001350  0.002712  0.000000  0.000000   \n",
              "1      0.197372  0.010159  0.025391  0.003078  0.007637  0.000042  0.002728   \n",
              "2      0.336494  0.009842  0.012436  0.000931  0.076778  0.195972  0.000000   \n",
              "3      0.321926  0.009510  0.008259  0.001698  0.048916  0.159222  0.000000   \n",
              "4      0.235577  0.012028  0.171329  0.003754  0.003048  0.031250  0.000000   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "24898  0.209835  0.045422  0.008781  0.006222  0.021400  0.003525  0.001793   \n",
              "24899  0.136776  0.119335  0.008301  0.003670  0.019718  0.001743  0.001202   \n",
              "24900  0.182735  0.085327  0.007359  0.005657  0.020821  0.003559  0.002514   \n",
              "24901  0.153652  0.241100  0.006588  0.002357  0.020512  0.001110  0.000496   \n",
              "24902  0.166553  0.003563  0.013710  0.001564  0.010273  0.007099  0.005623   \n",
              "\n",
              "       glass_doors  bathrooms  elevators  elevator_doors    stairs  storage  \\\n",
              "0         0.000000   0.000000   0.000000        0.000000  0.000000      0.0   \n",
              "1         0.000732   0.000000   0.000000        0.000000  0.000000      0.0   \n",
              "2         0.000000   0.000000   0.000000        0.000000  0.000000      0.0   \n",
              "3         0.000000   0.000000   0.000000        0.000000  0.000000      0.0   \n",
              "4         0.000000   0.000000   0.000000        0.000000  0.000000      0.0   \n",
              "...            ...        ...        ...             ...       ...      ...   \n",
              "24898     0.018581   0.015846   0.000668        0.010021  0.043221      0.0   \n",
              "24899     0.000488   0.000420   0.000313        0.000366  0.063194      0.0   \n",
              "24900     0.032402   0.015125   0.000950        0.016895  0.029358      0.0   \n",
              "24901     0.000435   0.000462   0.000206        0.000168  0.020435      0.0   \n",
              "24902     0.034466   0.002872   0.001091        0.013405  0.011791      0.0   \n",
              "\n",
              "       electrical  \n",
              "0             0.0  \n",
              "1             0.0  \n",
              "2             0.0  \n",
              "3             0.0  \n",
              "4             0.0  \n",
              "...           ...  \n",
              "24898         0.0  \n",
              "24899         0.0  \n",
              "24900         0.0  \n",
              "24901         0.0  \n",
              "24902         0.0  \n",
              "\n",
              "[24903 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fc63345-0fa8-42ce-98ac-cfb33767cf3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>background</th>\n",
              "      <th>room</th>\n",
              "      <th>hallway</th>\n",
              "      <th>kitchen</th>\n",
              "      <th>columns</th>\n",
              "      <th>mep</th>\n",
              "      <th>windows</th>\n",
              "      <th>doors</th>\n",
              "      <th>glass_doors</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>elevators</th>\n",
              "      <th>elevator_doors</th>\n",
              "      <th>stairs</th>\n",
              "      <th>storage</th>\n",
              "      <th>electrical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.591652</td>\n",
              "      <td>0.118961</td>\n",
              "      <td>0.007053</td>\n",
              "      <td>0.278271</td>\n",
              "      <td>0.001350</td>\n",
              "      <td>0.002712</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.752861</td>\n",
              "      <td>0.197372</td>\n",
              "      <td>0.010159</td>\n",
              "      <td>0.025391</td>\n",
              "      <td>0.003078</td>\n",
              "      <td>0.007637</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.367546</td>\n",
              "      <td>0.336494</td>\n",
              "      <td>0.009842</td>\n",
              "      <td>0.012436</td>\n",
              "      <td>0.000931</td>\n",
              "      <td>0.076778</td>\n",
              "      <td>0.195972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.450470</td>\n",
              "      <td>0.321926</td>\n",
              "      <td>0.009510</td>\n",
              "      <td>0.008259</td>\n",
              "      <td>0.001698</td>\n",
              "      <td>0.048916</td>\n",
              "      <td>0.159222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.543015</td>\n",
              "      <td>0.235577</td>\n",
              "      <td>0.012028</td>\n",
              "      <td>0.171329</td>\n",
              "      <td>0.003754</td>\n",
              "      <td>0.003048</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24898</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.614685</td>\n",
              "      <td>0.209835</td>\n",
              "      <td>0.045422</td>\n",
              "      <td>0.008781</td>\n",
              "      <td>0.006222</td>\n",
              "      <td>0.021400</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>0.001793</td>\n",
              "      <td>0.018581</td>\n",
              "      <td>0.015846</td>\n",
              "      <td>0.000668</td>\n",
              "      <td>0.010021</td>\n",
              "      <td>0.043221</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24899</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.644474</td>\n",
              "      <td>0.136776</td>\n",
              "      <td>0.119335</td>\n",
              "      <td>0.008301</td>\n",
              "      <td>0.003670</td>\n",
              "      <td>0.019718</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>0.001202</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.000420</td>\n",
              "      <td>0.000313</td>\n",
              "      <td>0.000366</td>\n",
              "      <td>0.063194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24900</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.597298</td>\n",
              "      <td>0.182735</td>\n",
              "      <td>0.085327</td>\n",
              "      <td>0.007359</td>\n",
              "      <td>0.005657</td>\n",
              "      <td>0.020821</td>\n",
              "      <td>0.003559</td>\n",
              "      <td>0.002514</td>\n",
              "      <td>0.032402</td>\n",
              "      <td>0.015125</td>\n",
              "      <td>0.000950</td>\n",
              "      <td>0.016895</td>\n",
              "      <td>0.029358</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24901</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.552479</td>\n",
              "      <td>0.153652</td>\n",
              "      <td>0.241100</td>\n",
              "      <td>0.006588</td>\n",
              "      <td>0.002357</td>\n",
              "      <td>0.020512</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>0.000496</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000462</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>0.020435</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24902</th>\n",
              "      <td>/content/drive/MyDrive/Processed_Floor_Plans/s...</td>\n",
              "      <td>0.727989</td>\n",
              "      <td>0.166553</td>\n",
              "      <td>0.003563</td>\n",
              "      <td>0.013710</td>\n",
              "      <td>0.001564</td>\n",
              "      <td>0.010273</td>\n",
              "      <td>0.007099</td>\n",
              "      <td>0.005623</td>\n",
              "      <td>0.034466</td>\n",
              "      <td>0.002872</td>\n",
              "      <td>0.001091</td>\n",
              "      <td>0.013405</td>\n",
              "      <td>0.011791</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24903 rows Ã— 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc63345-0fa8-42ce-98ac-cfb33767cf3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fc63345-0fa8-42ce-98ac-cfb33767cf3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fc63345-0fa8-42ce-98ac-cfb33767cf3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/Processed_Floor_Plans/smaller_images/pixel_counts.csv')\n",
        "#df=pd.read_csv('/content/drive/MyDrive/Processed_Floor_Plans/smaller_images/pixel_counts_128_128.csv')\n",
        "\n",
        "#df\n",
        "mask_files=df['filename'].values.tolist()\n",
        "len(mask_files)\n",
        "image_files = [filename.replace(\"temp_masks\", \"temp_images\") for filename in mask_files]\n",
        "image_files\n",
        "\n",
        "print(len(image_files))\n",
        "print(len(mask_files))\n",
        "\n",
        "display(df)\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "num_classes = 14\n",
        "Number_Category = 14\n",
        "validation_split=0.1\n",
        "debug=False\n",
        "\n",
        "image_size=512\n",
        "mask_category_list=[7,8]\n",
        "#mask_category_list=[6]\n",
        "debug=False\n",
        "iplot=False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image_files[22000],mask_files[22000]"
      ],
      "metadata": {
        "id": "syTvAypT9IC3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gXkWGmxmDoKT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def load_data(image_path, mask_path, mask_category_list, Number_Category=14,debug=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.round(tf.cast(mask, tf.float64) * Number_Category / 255.0)\n",
        "    condition = tf.math.logical_or(*[tf.equal(mask, val) for val in mask_category_list])\n",
        "    mask = tf.where(condition, 1, 0)\n",
        "\n",
        "    #mask = tf.where(tf.equal(mask, mask_category), 1, 0)\n",
        "    mask = tf.cast(mask, tf.uint8)\n",
        "\n",
        "\n",
        "    if debug:\n",
        "        image_filename = tf.strings.split(image_path, os.path.sep)[-1]\n",
        "        image_filename = tf.py_function(func=lambda x: x.numpy().decode('utf-8'), inp=[image_filename], Tout=tf.string)\n",
        "        return image, mask, image_filename\n",
        "    else:\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "def augment_data(image, mask):\n",
        "    # Apply data augmentation to the image and mask\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    #image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    #image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def create_dataset(image_paths, mask_paths, mask_category_list, batch_size, validation_split=0.2,debug=False,random_state=2023):\n",
        "    train_image_paths, val_image_paths,train_mask_paths,val_mask_paths = train_test_split(image_paths, mask_paths, test_size=validation_split, random_state=random_state)\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_mask_paths))\n",
        "    train_dataset = train_dataset.map(lambda x, y: load_data(x, y, mask_category_list=mask_category_list, debug=debug), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    train_dataset = train_dataset.map(augment_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
        "    train_dataset = train_dataset.batch(batch_size)\n",
        "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_mask_paths))\n",
        "    val_dataset = val_dataset.map(lambda x, y: load_data(x, y, mask_category_list=mask_category_list, debug=debug), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    val_dataset = val_dataset.batch(batch_size)\n",
        "    val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def plot_images_and_masks(dataset, num_batches):\n",
        "    # Take the specified number of batches from the dataset\n",
        "    dataset = dataset.take(num_batches)\n",
        "\n",
        "    for batch in dataset:\n",
        "        images, masks,files = batch\n",
        "\n",
        "        # Iterate over each image and mask in the batch\n",
        "        for i in range(images.shape[0]):\n",
        "            image = images[i]\n",
        "            mask = masks[i]\n",
        "\n",
        "            # Plot image and mask side by side\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "            axes[0].imshow(image)\n",
        "            axes[0].set_title('Image')\n",
        "            axes[0].axis('off')\n",
        "            axes[1].imshow(mask[:, :, 0], cmap='gray')\n",
        "            axes[1].set_title('Mask')\n",
        "            axes[1].axis('off')\n",
        "            axes[2].imshow(image)\n",
        "            axes[2].imshow(mask[:, :, 0], alpha=0.5)\n",
        "            axes[2].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6tVT3O3OEaeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c660ea-78ca-4cb4-cf8a-6f5dc68e88ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 512, 512, 3) <dtype: 'float32'> (8, 512, 512, 1) <dtype: 'uint8'>\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset = create_dataset(image_files, mask_files, mask_category_list=mask_category_list, batch_size=batch_size, validation_split=validation_split,debug=debug)\n",
        "num_batches=1\n",
        "val_dataset = val_dataset.take(num_batches)\n",
        "for batch in val_dataset:\n",
        "   images, masks = batch\n",
        "   print(images.shape,images.dtype,masks.shape,masks.dtype)\n",
        "   if iplot:\n",
        "      for i in range(images.shape[0]):\n",
        "                image = images[i]\n",
        "                mask = masks[i]\n",
        "                print(np.unique(mask.numpy()))\n",
        "                #ifile = files[i]\n",
        "                #print(ifile)\n",
        "\n",
        "                # Plot image and mask side by side\n",
        "                fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "                axes[0].imshow(image)\n",
        "                axes[0].set_title('Image')\n",
        "                axes[0].axis('off')\n",
        "                axes[1].imshow(mask[:, :, 0])\n",
        "                axes[1].set_title('Mask')\n",
        "                axes[1].axis('off')\n",
        "                axes[2].imshow(image)\n",
        "                axes[2].imshow(mask[:, :, 0], alpha=0.5)\n",
        "                axes[2].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "                plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yzXZV-LFLMQk"
      },
      "outputs": [],
      "source": [
        "# https://tensorlayer.readthedocs.io/en/latest/_modules/tensorlayer/cost.html#dice_coe\n",
        "def dice_coe(output, target, axis = None, smooth=1e-10):\n",
        "    output = tf.dtypes.cast( tf.math.greater(output, 0.5), tf. float32 )\n",
        "    target = tf.dtypes.cast( tf.math.greater(target, 0.5), tf. float32 )\n",
        "    inse = tf.reduce_sum(output * target, axis=axis)\n",
        "    l = tf.reduce_sum(output, axis=axis)\n",
        "    r = tf.reduce_sum(target, axis=axis)\n",
        "\n",
        "    dice = (2. * inse + smooth) / (l + r + smooth)\n",
        "    dice = tf.reduce_mean(dice, name='dice_coe')\n",
        "    return dice\n",
        "\n",
        "# https://www.kaggle.com/kool777/training-hubmap-eda-tf-keras-tpu\n",
        "def tversky(y_true, y_pred, alpha=0.7, beta=0.3, smooth=1):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + beta * false_pos + smooth)\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true, y_pred)\n",
        "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
        "    tv = tversky(y_true, y_pred)\n",
        "    return K.pow((1 - tv), gamma)\n",
        "\n",
        "get_custom_objects().update({\"focal_tversky\": focal_tversky_loss,'dice_coe':dice_coe})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbYAsrjOHCkf",
        "outputId": "d2c2f27d-eedc-4a06-a87b-112fcc77bdfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Parameters 10,071,501\n",
            "Total Parameters 10,115,501\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.set_image_data_format('channels_last')\n",
        "best_model_path=f'/content/drive/MyDrive/Processed_Floor_Plans/smaller_images/best_model_{image_size}.h5'\n",
        "with strategy.scope():\n",
        "\n",
        "  model = sm.Unet('efficientnetb0', classes=1, activation='sigmoid',input_shape=(image_size, image_size, 3))\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "                        loss = tf.keras.losses.BinaryCrossentropy(),#'focal_tversky',\n",
        "                        metrics=[dice_coe,'accuracy'])\n",
        "\n",
        "  checkpoint = ModelCheckpoint(best_model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "  reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=4,verbose=1, min_delta=0.00001)\n",
        "\n",
        "# Count the number of trainable parameters\n",
        "trainable_params = int(np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]))\n",
        "print(\"Trainable Parameters {:,}\".format(trainable_params) )\n",
        "\n",
        "# Count the total number of parameters\n",
        "total_params = int(np.sum([tf.keras.backend.count_params(w) for w in model.weights]))\n",
        "print(\"Total Parameters {:,}\".format(total_params) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCC7VSX7WAe9",
        "outputId": "7bde770c-8455-43a9-f3bd-a0ea5248f041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of accelerators:  1\n",
            "BATCH_SIZE:  8\n",
            "Epoch 1/20\n",
            "225/225 [==============================] - ETA: 0s - loss: 0.3928 - dice_coe: 0.0452 - accuracy: 0.9318\n",
            "Epoch 1: val_loss improved from inf to 0.31966, saving model to /content/drive/MyDrive/Processed_Floor_Plans/smaller_images/best_model_512.h5\n",
            "225/225 [==============================] - 381s 1s/step - loss: 0.3928 - dice_coe: 0.0452 - accuracy: 0.9318 - val_loss: 0.3197 - val_dice_coe: 0.0069 - val_accuracy: 0.9620 - lr: 1.0000e-04\n",
            "Epoch 2/20\n"
          ]
        }
      ],
      "source": [
        "# Train the model using the data generators\n",
        "epochs=20\n",
        "verbose=1\n",
        "\n",
        "batch_size = batch_size * strategy.num_replicas_in_sync\n",
        "\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "print(\"BATCH_SIZE: \", str(batch_size))\n",
        "\n",
        "train_dataset, val_dataset = create_dataset(image_files[0:20000], mask_files[0:20000], mask_category_list=mask_category_list, batch_size=batch_size, validation_split=validation_split,debug=False)\n",
        "\n",
        "K.clear_session()\n",
        "with strategy.scope():\n",
        "  history=model.fit(train_dataset, epochs=epochs, validation_data=val_dataset,callbacks=[checkpoint,reduce_lr_callback],verbose=verbose)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWccOhPkHJnf"
      },
      "outputs": [],
      "source": [
        "# Load the best saved model\n",
        "best_model = tf.keras.models.load_model(best_model_path, custom_objects={\"dice_coe\": dice_coe})\n",
        "\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "val_loss,dice_coe, val_acc, = model.evaluate(val_dataset)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation dice_coe:\", dice_coe)\n",
        "print(\"Validation Accuracy:\", val_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D08feMJYKFlC"
      },
      "outputs": [],
      "source": [
        "# Get the loss values from the history object\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the loss values\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, 'g', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Loss Function')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches=1\n",
        "#cutoff = 0.05\n",
        "val_dataset = val_dataset.take(num_batches)\n",
        "\n",
        "for batch in val_dataset:\n",
        "   images, masks = batch\n",
        "   predicted_masks = best_model.predict(images)\n",
        "   #predicted_masks = (predicted_masks > cutoff).astype(int)\n",
        "\n",
        "\n",
        "   print(images.shape,images.dtype,masks.shape,masks.dtype)\n",
        "   for i in range(images.shape[0]):\n",
        "            image = images[i]\n",
        "            mask = masks[i]\n",
        "            pred = predicted_masks[i]\n",
        "            print(np.unique(mask.numpy()))\n",
        "            #ifile = files[i]\n",
        "            #print(ifile)\n",
        "\n",
        "            # Plot image and mask side by side\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "            axes[0].imshow(image)\n",
        "            axes[0].set_title('Image')\n",
        "            axes[0].axis('off')\n",
        "            axes[1].imshow(image)\n",
        "            axes[1].imshow(mask[:, :, 0], alpha=0.5)\n",
        "            axes[1].axis('off')\n",
        "            axes[2].imshow(image)\n",
        "            axes[2].imshow(pred[:, :, 0], alpha=0.5,vmin=0,vmax=0.1)\n",
        "            axes[2].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "MtZo0CkoWhuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on full size image"
      ],
      "metadata": {
        "id": "c3S92T2DZROf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted_masks = best_model.predict(images)\n",
        "# #predicted_masks"
      ],
      "metadata": {
        "id": "9LitnriNdJkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_grid(shape, window=256, min_overlap=32):\n",
        "    \"\"\"\n",
        "        Return Array of size (N,4), where N - number of tiles,\n",
        "        2nd axis represente slices: x1,x2,y1,y2\n",
        "    \"\"\"\n",
        "    x, y,z = shape\n",
        "    nx = x // (window - min_overlap) + 1\n",
        "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
        "    x1[-1] = x - window\n",
        "    x2 = (x1 + window).clip(0, x)\n",
        "    ny = y // (window - min_overlap) + 1\n",
        "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
        "    y1[-1] = y - window\n",
        "    y2 = (y1 + window).clip(0, y)\n",
        "    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n",
        "\n",
        "    for i in range(nx):\n",
        "        for j in range(ny):\n",
        "            slices[i,j] = x1[i], x2[i], y1[j], y2[j]\n",
        "    return slices.reshape(nx*ny,4)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "patch_size = 512\n",
        "NEW_SIZE= 128\n",
        "scale=patch_size//NEW_SIZE\n",
        "overlap = 512\n",
        "\n",
        "\n",
        "filename='1.png'\n",
        "image_path='/content/drive/MyDrive/Processed_Floor_Plans/FP_raw/'+filename\n",
        "mask_path='/content/drive/MyDrive/Processed_Floor_Plans/FP_processed/'+filename\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "mask  = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)\n",
        "slices=make_grid(image.shape,window=patch_size,min_overlap=overlap)\n",
        "\n",
        "image_patches = []\n",
        "mask_patches = []\n",
        "\n",
        "slices=make_grid(image.shape,window=patch_size,min_overlap=overlap)\n",
        "#print(slices)\n",
        "for i,(x1,x2,y1,y2) in enumerate(slices):\n",
        "  try:\n",
        "        image_patch = image[x1:x2,y1:y2]\n",
        "\n",
        "\n",
        "        #print(image_patch.shape,mask_patch.shape)\n",
        "\n",
        "\n",
        "        image_patch= cv2.resize(image_patch, (NEW_SIZE, NEW_SIZE),interpolation = cv2.INTER_AREA)\n",
        "        image_patches.append(image_patch)\n",
        "  except:\n",
        "        print(image_path,i)\n",
        "        pass\n",
        "\n",
        "image_patches=np.array(image_patches)\n",
        "image_patches.shape\n",
        "\n",
        "pred_image=np.zeros_like(mask)\n",
        "n_pred=np.zeros_like(mask)\n",
        "predicted_masks = best_model.predict(images)\n",
        "print(pred_image.shape,predicted_masks.shape)\n",
        "for i,(x1,x2,y1,y2) in enumerate(slices):\n",
        "  tmp= cv2.resize(predicted_masks[i]*255, (y2-y1,x2-x1),interpolation = cv2.INTER_AREA)\n",
        "  pred_image[x1:x2,y1:y2]=tmp\n",
        "  n_pred[x1:x2,y1:y2]=n_pred[x1:x2,y1:y2]+1\n",
        "\n",
        "pred_image.shape\n",
        "\n",
        "plt.imshow(mask)\n",
        "plt.show()\n",
        "plt.imshow(pred_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FJ8RFURQY5Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(pred_image)"
      ],
      "metadata": {
        "id": "sJs64rpFhDVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1pI8RtPdujoGKyvY_o38OwHlYmMv49sQm",
      "authorship_tag": "ABX9TyPi/rVCRWikTm2geeGwnOBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}